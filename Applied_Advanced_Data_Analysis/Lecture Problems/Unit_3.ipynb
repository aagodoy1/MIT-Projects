{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a88dc7",
   "metadata": {},
   "source": [
    "# Criminal Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d46c1",
   "metadata": {},
   "source": [
    "# Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf65d19",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aff032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "\t[1, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "\t[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "\t[1, 1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
    "\t[0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "\t[1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "\t[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "\t[0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
    "\t[0, 0, 0, 0, 1, 0, 1, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a866953a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 14,  7, 21, 12, 11,  2,  7, 11,  5],\n",
       "       [14, 28,  2, 14,  6, 17,  2, 10, 19, 10],\n",
       "       [ 7,  2,  4, 10,  7,  2,  1,  1,  2,  2],\n",
       "       [21, 14, 10, 37, 20, 11,  2,  4,  8, 11],\n",
       "       [12,  6,  7, 20, 18,  4,  5,  2,  9,  9],\n",
       "       [11, 17,  2, 11,  4, 12,  1,  7, 11,  4],\n",
       "       [ 2,  2,  1,  2,  5,  1,  3,  1,  5,  2],\n",
       "       [ 7, 10,  1,  4,  2,  7,  1,  5,  8,  2],\n",
       "       [11, 19,  2,  8,  9, 11,  5,  8, 19,  9],\n",
       "       [ 5, 10,  2, 11,  9,  4,  2,  2,  9, 13]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@A@A@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565ddfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A == A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d8d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46, 59, 14, 62, 30, 40,  5, 21, 38, 25],\n",
       "       [59, 36, 28, 88, 57, 28, 10, 14, 30, 27],\n",
       "       [14, 28,  2, 14,  6, 17,  2, 10, 19, 10],\n",
       "       [62, 88, 14, 58, 33, 58, 11, 37, 68, 30],\n",
       "       [30, 57,  6, 33, 24, 32,  9, 20, 47, 32],\n",
       "       [40, 28, 17, 58, 32, 22,  4, 11, 19, 16],\n",
       "       [ 5, 10,  2, 11,  9,  4,  2,  2,  9, 13],\n",
       "       [21, 14, 10, 37, 20, 11,  2,  4,  8, 11],\n",
       "       [38, 30, 19, 68, 47, 19,  9,  8, 26, 33],\n",
       "       [25, 27, 10, 30, 32, 16, 13, 11, 33, 20]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@A@A@A@A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a2c1a",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e4b4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente:\n",
      "[[ 0  3]\n",
      " [ 0 10]\n",
      " [ 0 12]\n",
      " ...\n",
      " [99 77]\n",
      " [99 81]\n",
      " [99 85]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 'release_directed_graph.txt' tiene tus datos\n",
    "try:\n",
    "    # np.loadtxt es ideal para archivos simples y limpios\n",
    "    graph_data = np.loadtxt('release_directed_graph.txt', dtype=int)\n",
    "    \n",
    "    # graph_data ahora es un arreglo de NumPy que representa las aristas\n",
    "    print(\"Datos cargados exitosamente:\")\n",
    "    print(graph_data)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Asegúrate de que el archivo 'release_directed_graph.txt' exista.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al cargar el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffd2d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nodes\n",
    "len(np.unique(graph_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aristas\n",
    "len(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12804eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 19]\n",
      "Tiene auto ciclo\n"
     ]
    }
   ],
   "source": [
    "# Self Cycles?\n",
    "for arista in graph_data:\n",
    "    if arista[0] == arista[1]:\n",
    "        print(arista)\n",
    "        print('Tiene auto ciclo')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Tiene loops que no sea self loop? Problemos un llop tal que A -> B y B -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb1bd146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data[3][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15562972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph i: [ 0 84]\n",
      "graph j: [84  0]\n",
      "Tiene Cicly Simple\n"
     ]
    }
   ],
   "source": [
    "romper = False\n",
    "for i in range(len(graph_data)):\n",
    "    for j in range(len(graph_data)):\n",
    "        if i != j:\n",
    "            if graph_data[i][0] == graph_data[j][1] and  graph_data[i][1] == graph_data[j][0]:\n",
    "                print(f'graph i: {graph_data[i]}')\n",
    "                print(f'graph j: {graph_data[j]}')\n",
    "                print('Tiene Cicly Simple')\n",
    "                romper = True\n",
    "                break\n",
    "    if romper == True:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0703066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P value = 10.3\n"
     ]
    }
   ],
   "source": [
    "# ¿Cuanto vale P? \n",
    "\n",
    "promedios = []\n",
    "for nodo in range(len(np.unique(graph_data))):\n",
    "    #print(f'Leyendo Nodo: {nodo}')\n",
    "    promedio = 0\n",
    "    for arista in graph_data:\n",
    "        if nodo == arista[0]:\n",
    "            promedio+=1\n",
    "    promedios.append(promedio)\n",
    "p = np.average(promedios)\n",
    "\n",
    "print(f'P value = {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98761f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de aristas (e): 1030\n",
      "Número de nodos (n): 100\n",
      "Estimación de p (e/n^2) = 1030 / (100^2) = 0.103\n",
      "p con 5 cifras significativas: 0.10300\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular el número de aristas (e)\n",
    "num_edges = len(graph_data)\n",
    "\n",
    "# 2. Calcular el número de nodos (n)\n",
    "num_nodes = len(np.unique(graph_data.flatten()))\n",
    "\n",
    "# 3. Calcular la estimación de p\n",
    "p_mle = num_edges / (num_nodes ** 2)\n",
    "\n",
    "print(f\"Número de aristas (e): {num_edges}\")\n",
    "print(f\"Número de nodos (n): {num_nodes}\")\n",
    "print(f\"Estimación de p (e/n^2) = {num_edges} / ({num_nodes}^2) = {p_mle}\")\n",
    "\n",
    "# Para obtener el resultado con al menos 5 cifras significativas\n",
    "print(f\"p con 5 cifras significativas: {p_mle:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63bb89fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de aristas posibles (N_total): 10000\n",
      "Media Muestral (S_n): 0.103\n",
      "Media Poblacional (mu_n): 0.1\n",
      "Desviación estándar de la media muestral (sigma_n): 0.00300\n",
      "----------------------------------------\n",
      "Estadístico Z calculado: 1.000\n",
      "----------------------------------------\n",
      "P-valor (5 cifras significativas): 0.31731\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "p_null = 0.1\n",
    "N_total = num_nodes ** 2\n",
    "print(f\"Total de aristas posibles (N_total): {N_total}\")\n",
    "\n",
    "# 1.2. Media Muestral (S_n = p_mle)\n",
    "S_n = num_edges / N_total\n",
    "print(f\"Media Muestral (S_n): {S_n}\")\n",
    "\n",
    "# 1.3. Media Poblacional bajo H0 (mu_n)\n",
    "mu_n = p_null\n",
    "print(f\"Media Poblacional (mu_n): {mu_n}\")\n",
    "\n",
    "# 1.4. Desviación Estándar de la Media Muestral (sigma_n)\n",
    "# Fórmula: sigma_n = sqrt( p_0 * (1 - p_0) / N_total )\n",
    "sigma_squared = p_null * (1 - p_null)\n",
    "sigma_n = np.sqrt(sigma_squared / N_total)\n",
    "print(f\"Desviación estándar de la media muestral (sigma_n): {sigma_n:.5f}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# --- 2. CÁLCULO DEL ESTADÍSTICO DE PRUEBA Z ---\n",
    "\n",
    "# Fórmula: Z = | S_n - mu_n | / sigma_n\n",
    "Z_statistic = np.abs(S_n - mu_n) / sigma_n\n",
    "print(\"-\" * 40)\n",
    "print(f\"Estadístico Z calculado: {Z_statistic:.3f}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# --- 3. CÁLCULO DEL P-VALOR (PRUEBA BILATERAL) ---\n",
    "\n",
    "# P(Z > Z_statistic) se calcula con la función de supervivencia (sf) de la normal.\n",
    "# El p-valor bilateral es 2 * P(Z > Z_statistic)\n",
    "p_value = 2 * norm.sf(Z_statistic)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"P-valor (5 cifras significativas): {p_value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c4a47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af1fa24b",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61a7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularidad Q = -0.204\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matriz de adyacencia (según la imagen)\n",
    "A = np.array([[0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "\t[1, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "\t[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "\t[1, 1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
    "\t[0, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "\t[1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "\t[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "\t[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "\t[0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
    "\t[0, 0, 0, 0, 1, 0, 1, 0, 1, 0]])\n",
    "\n",
    "# Comunidades (0 o 1)\n",
    "# tipo 1 -> comunidad 0, tipo 2 -> comunidad 1\n",
    "communities = np.array([0,1,0,1,0,1,0,1,0,1])\n",
    "\n",
    "# Grados\n",
    "k = np.sum(A, axis=1)\n",
    "\n",
    "# Número total de aristas\n",
    "m = np.sum(k) / 2\n",
    "\n",
    "# Cálculo de la modularidad\n",
    "Q = 0\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(A)):\n",
    "        if communities[i] == communities[j]:  # misma comunidad\n",
    "            Q += A[i,j] - (k[i]*k[j])/(2*m)\n",
    "\n",
    "Q /= 2*m\n",
    "\n",
    "print(f\"Modularidad Q = {Q:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3adb43c",
   "metadata": {},
   "source": [
    "# Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d20390",
   "metadata": {},
   "source": [
    "## Page 4: Eigen Vector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72c4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centralidad de Autovector (Autovector DERECHO) ---\n",
      "Nodo 1: 1.00000000\n",
      "Nodo 2: 0.00000095\n",
      "Nodo 3: 0.00000095\n",
      "Nodo 4: 0.00000095\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0]])\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# 3. Calcular la Centralidad de Autovector\n",
    "# networkx.eigenvector_centrality calcula el autovector derecho, \n",
    "# el cual está relacionado con el grado de SALIDA.\n",
    "centralidad = nx.eigenvector_centrality(G)\n",
    "\n",
    "print(\"--- Centralidad de Autovector (Autovector DERECHO) ---\")\n",
    "# Mostrar resultados\n",
    "for nodo, valor in sorted(centralidad.items()):\n",
    "    print(f\"Nodo {nodo+1}: {valor:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb5e46a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centralidad de Autovector (Autovector DERECHO) ---\n",
      "Nodo 1: 0.50000000\n",
      "Nodo 2: 0.50000000\n",
      "Nodo 3: 0.50000000\n",
      "Nodo 4: 0.50000000\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1,1,1],\n",
    "    [0,0,0,0],\n",
    "    [0,0,0,0],\n",
    "    [0,0,0,0]])\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# 3. Calcular la Centralidad de Autovector\n",
    "# networkx.eigenvector_centrality calcula el autovector derecho, \n",
    "# el cual está relacionado con el grado de SALIDA.\n",
    "centralidad = nx.eigenvector_centrality(G)\n",
    "\n",
    "print(\"--- Centralidad de Autovector (Autovector DERECHO) ---\")\n",
    "# Mostrar resultados\n",
    "for nodo, valor in sorted(centralidad.items()):\n",
    "    print(f\"Nodo {nodo+1}: {valor:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97352842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centralidad de Autovector (Autovector DERECHO) ---\n",
      "Nodo 1: 0.79917149\n",
      "Nodo 2: 0.34704703\n",
      "Nodo 3: 0.34704703\n",
      "Nodo 4: 0.34704703\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1,1,1],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0]])\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# 3. Calcular la Centralidad de Autovector\n",
    "# networkx.eigenvector_centrality calcula el autovector derecho, \n",
    "# el cual está relacionado con el grado de SALIDA.\n",
    "centralidad = nx.eigenvector_centrality(G)\n",
    "\n",
    "print(\"--- Centralidad de Autovector (Autovector DERECHO) ---\")\n",
    "# Mostrar resultados\n",
    "for nodo, valor in sorted(centralidad.items()):\n",
    "    print(f\"Nodo {nodo+1}: {valor:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57a50c",
   "metadata": {},
   "source": [
    "## Page 5: Katz Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[0,1,1,1],\n",
    "    [0,0,0,0],\n",
    "    [0,0,0,0],\n",
    "    [0,0,0,0]])\n",
    "A@A@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30bd2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de Centralidad de Katz (sin redondear):\n",
      "Node 0: 0.464739\n",
      "Node 1: 0.511213\n",
      "Node 2: 0.511213\n",
      "Node 3: 0.511213\n",
      "\n",
      "Valores de Centralidad de Katz (redondeados a 3 cifras significativas):\n",
      "Node 0: 0.465\n",
      "Node 1: 0.511\n",
      "Node 2: 0.511\n",
      "Node 3: 0.511\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Definir la matriz de adyacencia\n",
    "A = np.array([\n",
    "    [0, 1, 1, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Crear un grafo dirigido a partir de la matriz de adyacencia\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# Calcular la centralidad de Katz con los valores predeterminados\n",
    "# de alpha=0.1 y beta=1.0. La función devuelve un diccionario.\n",
    "# La normalización es por defecto a la norma L2.\n",
    "katz_centrality = nx.katz_centrality(G, alpha=0.1, beta=1.0)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Valores de Centralidad de Katz (sin redondear):\")\n",
    "for node, centrality in katz_centrality.items():\n",
    "    print(f\"Node {node}: {centrality:.6f}\")\n",
    "    \n",
    "# Imprimir los resultados redondeados a 3 cifras significativas\n",
    "print(\"\\nValores de Centralidad de Katz (redondeados a 3 cifras significativas):\")\n",
    "for node, centrality in katz_centrality.items():\n",
    "    print(f\"Node {node}: {centrality:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671d6ea",
   "metadata": {},
   "source": [
    "## 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ebc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de Centralidad de Katz (sin redondear):\n",
      "Node 0: 0.490292\n",
      "Node 1: 0.362204\n",
      "Node 2: 0.362204\n",
      "Node 3: 0.362204\n",
      "Node 4: 0.362204\n",
      "Node 5: 0.358582\n",
      "Node 6: 0.325984\n",
      "\n",
      "Valores de Centralidad de Katz (redondeados a 3 cifras significativas):\n",
      "Node 0: 0.490\n",
      "Node 1: 0.362\n",
      "Node 2: 0.362\n",
      "Node 3: 0.362\n",
      "Node 4: 0.362\n",
      "Node 5: 0.359\n",
      "Node 6: 0.326\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1, 0]]\n",
    "    )\n",
    "\n",
    "# Crear un grafo dirigido a partir de la matriz de adyacencia\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# Calcular la centralidad de Katz con los valores predeterminados\n",
    "# de alpha=0.1 y beta=1.0. La función devuelve un diccionario.\n",
    "# La normalización es por defecto a la norma L2.\n",
    "katz_centrality = nx.katz_centrality(G, alpha=0.1, beta=1.0)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Valores de Centralidad de Katz (sin redondear):\")\n",
    "for node, centrality in katz_centrality.items():\n",
    "    print(f\"Node {node}: {centrality:.6f}\")\n",
    "    \n",
    "# Imprimir los resultados redondeados a 3 cifras significativas\n",
    "print(\"\\nValores de Centralidad de Katz (redondeados a 3 cifras significativas):\")\n",
    "for node, centrality in katz_centrality.items():\n",
    "    print(f\"Node {node}: {centrality:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b68468ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralidad de PageRank (α=0.85):\n",
      "Nodo 0: 0.343\n",
      "Nodo 1: 0.122\n",
      "Nodo 2: 0.122\n",
      "Nodo 3: 0.122\n",
      "Nodo 4: 0.122\n",
      "Nodo 5: 0.0998\n",
      "Nodo 6: 0.07\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Matriz de Adyacencia A del problema anterior\n",
    "A = np.array([\n",
    "    [0, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "# 1. Crear el grafo dirigido (DiGraph)\n",
    "# PageRank opera sobre grafos dirigidos.\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# 2. Calcular la Centralidad de PageRank\n",
    "# Usamos el valor por defecto alpha (α) = 0.85.\n",
    "# El resto de los parámetros (como el vector de personalization) son los predeterminados.\n",
    "# PageRank está normalizado por definición (la suma de las centralidades es 1).\n",
    "pagerank_c = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# 3. Formatear la salida para tres cifras significativas\n",
    "print(\"Centralidad de PageRank (α=0.85):\")\n",
    "\n",
    "# La función pagerank devuelve un diccionario: {nodo: valor_pagerank}\n",
    "for node, centrality in pagerank_c.items():\n",
    "    # Usamos el formato ':.3g' para asegurar la precisión de al menos 3 cifras significativas.\n",
    "    formatted_centrality = f\"{centrality:.3g}\"\n",
    "    print(f\"Nodo {node}: {formatted_centrality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aae40aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralidad de HITS (Hubs y Authorities):\n",
      "=========================================\n",
      "\n",
      "Scores de Hubs (v):\n",
      "Nodo 0: 0.254\n",
      "Nodo 1: 0.132\n",
      "Nodo 2: 0.132\n",
      "Nodo 3: 0.132\n",
      "Nodo 4: 0.132\n",
      "Nodo 5: 0.0868\n",
      "Nodo 6: 0.132\n",
      "Scores de Authorities (w):\n",
      "Nodo 0: 0.254\n",
      "Nodo 1: 0.132\n",
      "Nodo 2: 0.132\n",
      "Nodo 3: 0.132\n",
      "Nodo 4: 0.132\n",
      "Nodo 5: 0.132\n",
      "Nodo 6: 0.0868\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Matriz de Adyacencia A\n",
    "A = np.array([\n",
    "    [0, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "# 1. Crear el grafo dirigido (DiGraph)\n",
    "# HITS, como PageRank, opera sobre grafos dirigidos.\n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph)\n",
    "\n",
    "# 2. Calcular la Centralidad HITS (Hubs y Authorities)\n",
    "# La función networkx.hits devuelve una tupla de dos diccionarios: (hub_scores, authority_scores)\n",
    "# La normalización (suma=1) está implícita en la implementación de networkx.\n",
    "hub_scores, authority_scores = nx.hits(G)\n",
    "\n",
    "# 3. Formatear la salida para tres cifras significativas\n",
    "\n",
    "print(\"Centralidad de HITS (Hubs y Authorities):\")\n",
    "print(\"=========================================\")\n",
    "\n",
    "\n",
    "print(\"\\nScores de Hubs (v):\")\n",
    "# Imprimir los Scores de Hubs (v)\n",
    "for node in sorted(hub_scores.keys()):\n",
    "    centrality = hub_scores[node]\n",
    "    # Usamos el formato ':.3g' para asegurar la precisión de 3 cifras significativas.\n",
    "    formatted_centrality = f\"{centrality:.3g}\"\n",
    "    print(f\"Nodo {node}: {formatted_centrality}\")\n",
    "\n",
    "# Imprimir los Scores de Authorities (w)\n",
    "print(\"Scores de Authorities (w):\")\n",
    "for node in sorted(authority_scores.keys()):\n",
    "    centrality = authority_scores[node]\n",
    "    # Usamos el formato ':.3g' para asegurar la precisión de 3 cifras significativas.\n",
    "    formatted_centrality = f\"{centrality:.3g}\"\n",
    "    print(f\"Nodo {node}: {formatted_centrality}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b2a1b",
   "metadata": {},
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637087b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aristas en el MST (Nodos: 1, 2, 3, 4): [(1, 2, {'weight': 3}), (1, 4, {'weight': 5}), (3, 4, {'weight': 3})]\n",
      "La suma de todos los pesos de las aristas en el Árbol de Expansión Mínima es: 11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# 1. Definir la Matriz de Distancias D (Corregida)\n",
    "# Los nodos son {1, 2, 3, 4}.\n",
    "# D[i, j] es la distancia entre el nodo i+1 y el nodo j+1.\n",
    "D_matrix = np.array([\n",
    "    [0, 3, 6, 5],\n",
    "    [3, 0, 5, 6],\n",
    "    [6, 5, 0, 3],\n",
    "    [5, 6, 3, 0]\n",
    "])\n",
    "\n",
    "# 2. Crear un grafo de NetworkX a partir de la matriz\n",
    "# Usamos un grafo completo (Complete Graph) donde las aristas son las distancias.\n",
    "G = nx.from_numpy_array(D_matrix)\n",
    "\n",
    "# NetworkX usa índices de 0 a 3 por defecto.\n",
    "# Si queremos que los nodos se llamen 1, 2, 3, 4:\n",
    "mapping = {i: i + 1 for i in G.nodes}\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "\n",
    "# 3. Encontrar el Árbol de Expansión Mínima (MST)\n",
    "# 'weight' es el atributo por defecto que networkx usa para el peso.\n",
    "mst_graph = nx.minimum_spanning_tree(G, algorithm='kruskal', weight='weight')\n",
    "\n",
    "# 4. Calcular la suma de los pesos de las aristas del MST\n",
    "mst_weight = mst_graph.size(weight='weight')\n",
    "\n",
    "# 5. Imprimir el resultado\n",
    "\n",
    "print(f\"Aristas en el MST (Nodos: 1, 2, 3, 4): {mst_graph.edges.data()}\")\n",
    "print(f\"La suma de todos los pesos de las aristas en el Árbol de Expansión Mínima es: {mst_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3465d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2140de0da50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mst_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad13b2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6045b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de Fiedler (Vector Propio de lambda_2, normalizado a 1):\n",
      "Node 1: -0.371\n",
      "Node 2: -0.336\n",
      "Node 3: -0.235\n",
      "Node 4: -0.336\n",
      "Node 5: 0.012\n",
      "Node 6: 0.256\n",
      "Node 7: 0.451\n",
      "Node 8: 0.559\n",
      "\n",
      "Verificación de la Norma L2 (debería ser 1.0): 1.00000\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# 1. Definir el grafo G a partir de la imagen\n",
    "# El grafo tiene 8 nodos. Las aristas son:\n",
    "# Ciclo: (1, 2), (2, 3), (3, 4), (4, 1)\n",
    "# Camino: (3, 5), (5, 6), (6, 7), (7, 8)\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([\n",
    "    (1, 2), (2, 3), (3, 4), (4, 1), # Ciclo C4\n",
    "    (3, 5), (5, 6), (6, 7), (7, 8)  # Camino P5 (conectado en 3)\n",
    "])\n",
    "\n",
    "# 2. Calcular el vector de Fiedler (vector propio de la Matriz Laplaciana)\n",
    "# El fiedler_vector es el vector propio correspondiente al segundo valor propio más pequeño (lambda_2).\n",
    "# networkx ya normaliza el vector tal que su norma euclidiana (norma L2) es 1.\n",
    "try:\n",
    "    fiedler_vector = nx.linalg.algebraicconnectivity.fiedler_vector(G)\n",
    "except nx.NetworkXUnfeasible:\n",
    "    # Este error podría ocurrir si el grafo no está conectado, pero este sí lo está.\n",
    "    print(\"Error: El grafo no está conectado.\")\n",
    "    # El vector propio correspondiente a lambda_1 (el más pequeño) siempre es constante.\n",
    "    # El vector propio correspondiente a lambda_2 (el segundo más pequeño) es el vector de Fiedler, \n",
    "    # y existe si el grafo no es trivial y tiene más de un componente conectado.\n",
    "    \n",
    "# 3. Formatear y redondear los resultados a tres cifras significativas\n",
    "# networkx devuelve el vector en el orden del índice de los nodos: [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "rounded_vector = [round(val, 3) for val in fiedler_vector]\n",
    "\n",
    "# 4. Imprimir los resultados\n",
    "print(\"Vector de Fiedler (Vector Propio de lambda_2, normalizado a 1):\")\n",
    "for i, val in enumerate(rounded_vector):\n",
    "    print(f\"Node {i + 1}: {val}\")\n",
    "\n",
    "# 5. Para verificar la normalización (opcional)\n",
    "norm_check = np.linalg.norm(fiedler_vector)\n",
    "print(f\"\\nVerificación de la Norma L2 (debería ser 1.0): {norm_check:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88af0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3715 -0.3356 -0.235  -0.3356  0.0117  0.2561  0.451   0.5589]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.linalg.algebraicconnectivity import fiedler_vector\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([\n",
    "    (1,2),(2,3),(3,4),(4,1),\n",
    "    (3,5),(5,6),(6,7),(7,8)\n",
    "])\n",
    "\n",
    "v = fiedler_vector(G, normalized=False)\n",
    "v = np.array(v)\n",
    "v = v / np.sqrt(np.sum(v**2))\n",
    "print(np.round(v, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634feb18",
   "metadata": {},
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bdf9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.000004000004e-07"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 200*10**3\n",
    "n = 10**6\n",
    "p = 2*m/(n*(n-1))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e7436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micromasters_ml_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
